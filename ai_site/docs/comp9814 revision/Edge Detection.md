# 边缘检测（Edge Detection）

## 一、边缘检测的基本思想（一阶导/二阶导）

> **核心概念：边缘 = 像素强度变化很快的地方。**

* 图片可以看成函数 (f(x,y))，灰度值随位置变化。
* 在一维情况下，沿着一条水平线看灰度：

  * (f(x))：原始强度曲线
  * (f'(x))：一阶导数（变化率）
  * 在**变化最快的地方**，(|f'(x)|) 会出现峰值 ⇒ 那里是**边缘**。

**典型“流程图式”表述（可以直接写在考卷上）：**

1. 对灰度函数求导：(f'(x))
2. 取绝对值：(|f'(x)|)
3. 大于某个阈值 T 的点，认为是边缘：(|f'(x)| > T)
4. 再做一下 local maximum 检测，只保留局部最大值，避免重复边。

> 这一小段通常出现在“解释边缘检测的基本思想”或者“解释图中 f、f’、|f’|、Threshold 的关系”。

---

## 二、Laplacian（拉普拉斯）边缘检测

### 1. 二阶导 + 离散形式

连续形式：
\[
\nabla^2 f = \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2}
\]

离散近似（只看邻居）：

\[
\nabla^2 f(x,y) \approx f(x+1,y) + f(x-1,y) + f(x,y+1) + f(x,y-1) -4 f(x,y)
\]

对应的 3×3 kernel（常考的那个）：

\[
\begin{bmatrix}
0 & -1 & 0 \\
-1 & 4 & -1 \\
0 & -1 & 0
\end{bmatrix}
\]

以及“更敏感”的 8 邻域版本（有时会给出）：

\[
\begin{bmatrix}
-1 & -1 & -1 \\
-1 & 8  & -1 \\
-1 & -1 & -1
\end{bmatrix}
\]

**性质要会说：**

* 平坦区域（强度几乎不变）：卷积结果 (\approx 0)
* 强度有突变：输出为较大的正/负值 ⇒ 对应边缘
* 对噪声也很敏感，所以**往往要先平滑（如 Gaussian）再用 Laplacian**（LoG 的思路）。

### 2. 计算题模板：Laplacian 卷积

题型：给你一个 3×3 patch 和 Laplacian kernel，问输出值。

> **模板过程：**
>
> 1. 把 kernel 旋转 180°（Laplacian 对称，旋不旋一样，直接相乘就行）
> 2. 对应位置相乘，再全部相加
> 3. 输出就是中心像素的新值

**例（你可以在脑子里练习）：**

patch：
\[
\begin{bmatrix}
10 & 10 & 10 \\
10 & 50 & 10 \\
10 & 10 & 10
\end{bmatrix}
\]
kernel：
\[
\begin{bmatrix}
0 & -1 & 0 \\
-1 & 4 & -1 \\
0 & -1 & 0
\end{bmatrix}
\]

计算中心点输出：
\[
\begin{aligned}
0\cdot10 + (-1)\cdot10 + 0\cdot10 \\+ (-1)\cdot10 + 4\cdot50 + (-1)\cdot10 \\+ 0\cdot10 + (-1)\cdot10 + 0\cdot10\\
= 200 - 40 = 160
\end{aligned}
\]

* 结果很大 ⇒ 中心像素是边缘位置。
* 考试时写清楚“逐项乘加”的过程即可。

---

## 三、Canny 边缘检测（重点流程题）

Slides 里给了 Canny 的**4 个主要步骤**：

> 1. Gaussian filter 平滑去噪
> 2. 计算梯度：(G_x, G_y)，得到梯度大小和方向
> 3. 阈值和非极大值抑制（suppress 非强边缘）
> 4. Double threshold + hysteresis：强/弱/非边缘分类

你答题时可以展开为下面版本（更像“满分模板”）：

### Step 1：Gaussian 平滑去噪

* 用 **Gaussian kernel** 对图像做卷积：
  \[
  G(x,y) = \frac{1}{2\pi\sigma^2} e^{-\frac{x^2 + y^2}{2\sigma^2}}
  \]

* 比普通均值滤波好：**中心权重大、边缘权重小**，有效抑制噪声，又尽量保留结构。

### Step 2：计算梯度（Gx, Gy）

用 Sobel 或类似算子计算 **水平/垂直方向导数**：

* ($G_x$)：x 方向梯度（检测垂直边）
* ($G_y$)：y 方向梯度（检测水平边）

然后：
\[
\text{mag} = \sqrt{G_x^2 + G_y^2}, \quad \theta = \arctan\left(\frac{G_y}{G_x}\right)
\]

**考点：**

* mag 大 ⇒ 强边缘
* θ 决定边缘方向（竖直 / 水平 / 斜边）

**小计算题模板：**

给定 ($G_x$ = 3, $G_y$ = 4)：

* mag = \(\sqrt{3^2 + 4^2} = 5\)
* θ = \(\arctan(4/3)\) ≈ 53°（接近竖直方向的边）

### Step 3：Non-maximum suppression（非极大值抑制）

* 沿着梯度方向（垂直于边缘）看相邻两个像素：

  * 若当前像素的 mag **不是局部最大** ⇒ 设为 0（抑制）
* 目的：**让边缘细到 1 像素宽**，避免宽边/厚边。

考试问“为什么要做 non-maximum suppression”：

> 因为梯度在边缘附近一条带状区域都可能很大，NMS 只保留局部最大值，让边缘细而明确，减少错误边。

### Step 4：Double threshold & Hysteresis（双阈值 + 连接）

Slides 说：有两个阈值 minVal 和 maxVal：

* mag ≥ maxVal ⇒ **强边缘**（肯定是边）
* mag < minVal ⇒ **非边缘**（直接丢）
* 中间 ⇒ **弱边缘**，要看是否和强边缘相连：

  * 若与强边缘连通 ⇒ 保留（真实边的一部分）
  * 否则 ⇒ 丢弃（噪声或孤立响应）

**考点问法：**

* “解释 Canny 的双阈值有什么作用？”

  * 答：区分强/弱边缘，通过连接规则保留连续的真实边缘，同时丢弃孤立噪声响应，兼顾**检测率**和**噪声鲁棒性**。

---

## 四、考试常见问法 + 回答骨架

### 1. 问：“解释边缘检测的基本思想”

答题骨架：

1. 边缘是图像中亮度变化剧烈的位置
2. 用导数检测变化：一阶导数 |f’(x)| 峰值处是边缘
3. 实际中对 2D 图像计算梯度 ((G_x,G_y))，用 mag + 阈值判定
4. 若是 Laplacian，再补一句“利用二阶导数零交叉/大值检测边缘”

---

### 2. 问：“写出/解释 Laplacian edge detector 的离散形式，并给出 kernel”

骨架：

1. 写式子 ($\nabla^2 f = \frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2}$)
2. 离散近似：
   \[
   \nabla^2 f(x,y) \approx f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)
   \]
3. 给出 3×3 kernel（0 -1 0; -1 4 -1; 0 -1 0）
4. 说明：平坦区域结果≈0；强度突变处输出大 ⇒ 边缘；敏感噪声，常配合平滑。

---

### 3. 问：“简述 Canny edge detector 的步骤，并说明每一步的目的”

可以直接写成 4 条：

1. **Gaussian 平滑**：抑制噪声，避免噪声产生虚假边缘
2. **计算梯度**（Sobel 等）：得到边缘强度和方向
3. **非极大值抑制**：沿梯度方向只保留局部最大值，得到细边
4. **双阈值 + hysteresis**：用高/低两阈值区分强/弱边缘，通过连通性保留真实边，去掉孤立噪声

---
# Filtering（图像滤波）

## 1. 从矩阵视角理解 filtering

* 灰度图可以看成一个二维数组 (I(x, y))，每个元素就是像素强度。
* **滤波**就是拿一个小矩阵（kernel / filter，比如 3×3）在图上滑动，对覆盖到的像素做某种运算（平均、加权和、求导等），把结果写回中心像素。
* 这种“滑窗 + 乘加”的操作本质就是 **卷积（convolution）**：

\[
S(j, k) = (K * I)(j, k) = \sum_m \sum_n K(m, n), I(j+m, k+n)
\]

理解成：

> 把 kernel 倒过来 / 对齐当前位置，逐元素相乘再求和，得到“过滤后”的像素值。

在 CNN 里，卷积层就是用很多不同的 filter 来抽取不同特征（边缘、纹理、形状等）。

---

## 2. 噪声去除：平滑 / 平均滤波（Smoothing & Averaging）

### 2.1 为什么要平滑？

* 实际图像总会有噪声（感光元件、压缩、传输等）。
* **平滑**的目的：

  * 减少随机噪声、孤立亮点/暗点。
  * 代价：会同时模糊真实边缘（这是考题常问的 trade-off）。

### 2.2 均值滤波（Averaging filter）

思路：用邻域像素的平均值替代中心像素。

以 3×3 滤波器为例：

1. 取图像的一个 3×3 小窗口。
2. 求这 9 个值的平均值。
3. 把窗口中心的像素值替换成这个平均值。
4. 窗口向右/向下滑动，重复操作（这就是“滑动 + 平均 = 卷积”）。

举个非常简单的例子：

原始：

\[
\begin{bmatrix}
10 & 10 & 10 \\
10 & 255 & 10 \\
10 & 10 & 10 \\
\end{bmatrix}
\]

中心 255 明显是噪声点。
3×3 平均：\((8\times 10 + 255)/9 \approx 37\)，比 255 小很多，噪声被“抹平”。

> **要点记忆**：
>
> * 均值滤波是线性滤波。
> * 能去除随机噪声，但会模糊边缘。
> * 在习题中，经常要你“给出平滑后的矩阵”或“用阈值判断结果黑/白”（见 Week7 Ex. Q2）。

---

## 3. 高斯滤波（Gaussian filtering）

均值滤波所有邻居权重相同，容易“把边缘也当噪声平均掉”。
**高斯滤波**通过一个类似钟形曲线的权重分布，让“越靠中心的像素权重大”，既平滑又尽量保留结构。

二维高斯核：

\[
G(x,y)=\frac{1}{2\pi\sigma^2}\exp\Big(-\frac{x^2+y^2}{2\sigma^2}\Big)
\]

* \((x,y)\)：相对窗口中心的坐标
* \(\sigma\)：标准差，越大越模糊

示例 3×3 高斯核（\(\sigma \approx 1\)）：

\[
\frac{1}{16}
\begin{bmatrix}
1 & 2 & 1 \\
2 & 4 & 2 \\
1 & 2 & 1 \\
\end{bmatrix}
\]

> **要点记忆：**
>
> * 高斯滤波也是线性卷积，但权重服从高斯分布。
> * 比简单平均更“自然”，是 Canny 边缘检测的第一步。

---

## 5. CNN 里的 filtering（卷积层 & 池化层）

课程后半部分会把 image filtering 和 CNN 联系起来：

* 卷积层：对输入图像用很多 learnable filter 进行卷积，自动学出能区分类别的特征（底层边缘、中层纹理、高层物体部件）。
* 池化层（pooling）：用 max/average filter 做 **下采样**，降低分辨率但保留重要特征。
* padding & stride：改变输出 feature map 的大小、控制信息损失。

你可以把这些都看作是“更高级的 filtering”：

> 图像处理课里的核是**手工设定**（比如 Laplacian、Gaussian），
> CNN 里的核是通过训练 **自动学习** 出来的。

---

## 6. 考试常见问法 & 记忆小结

1. **概念题：**

   * 什么是图像滤波？
   * 均值滤波和高斯滤波有什么区别？
   * Laplacian 核长什么样？有什么作用？
2. **计算题：**

   * 给出一个小矩阵和一个 kernel，让你手算卷积结果。
   * 给出一个 3×3/5×5 邻域，让你算平滑后的值并做阈值分类（黑/白）。
   * 给出一个边缘检测核，让你判定输出哪个位置是边缘。
3. **综合理解：**

   * 为什么在 Canny 里要先 Gaussian 再算梯度？
   * 为什么平滑会模糊边缘，但又是必要的？

**一页记忆版：**

* Filtering = 用 kernel 对图像做卷积，改变每个像素为“周围像素的函数”。
* Smoothing：

  * Mean filter：所有权重相等 → 去噪 + 模糊。
  * Gaussian filter：中心权重大 → 更自然、Canny 第一步。
* Edge filters：

  * 一阶（梯度）：\(G_x,G_y,|\nabla I|\)，大值+局部极大 = 边缘。
  * 二阶（Laplacian）：\(0,-1,4,-1,0\)，突出强度变化。
* Canny：Gaussian → gradient → non-max suppression → double threshold + hysteresis。
* CNN：卷积层 + 池化层 = “可学习的 filtering”。

---


# ✅ **Levels of AI（AI 的层级）考点总结**

在课程中，AI 的能力被分成 **七个层级（Powell, 2024）**。该体系用于描述 **一个智能体从简单反射到具备社会性、道德性意图推理的完整递进过程**，同时也是考试高频题，因为它与“Explainable AI”“Human-aligned AI”“Interactive RL”“机器人行为解释”等内容强关联。

## **Level 0 – 无 AI（No AI）**

**系统完全被动，无自主行为。**

* 没有学习能力
* 没有决策能力
* 完全依赖预设逻辑或人类指令

**例：** 最基本的机械开关、传统家电。

---

## **Level 1 – 反应式（Reactive AI）**

**基于即时传感器输入做出反射式决策，没有记忆。**

* 无内部状态
* 无长期预测
* 类似简单规则系统（IF-THEN）

**例：** 线路跟踪机器人、避障机器人。

---

## **Level 2 – 基于状态的 AI（State-based AI）**

**具备内部状态，可以进行简单的推理或条件判断。**

* 能够记住过去
* 可以进行有限规划
* 相当于强化学习中的 Markov 状态

**例：** 根据电量、位置、任务状态决定下一步动作的机器人。

---

## **Level 3 – 基于目标的 AI（Goal-Driven AI）**

**能够理解目标，并以此为依据更新策略。**

* 不再是规则累加，而是以“达成目标”为核心
* 大部分 RL 代理处于此级别（Maximize cumulative reward）
* 可以规划序列动作

**例：** 迷宫导航、任务执行型机器人。

---

## **Level 4 – 基于模型的 AI（Model-Based AI）**

**具备对世界的显式模型（Model），能够预测未来并规划。**

* 能模拟环境：（下一状态、奖励）
* Model-based RL, MPC
* 相比 Level 3 具备“前瞻性”与“假设推理（What-if analysis）”

**例：** 能预测碰撞风险并提前绕行的自主车。

---

## **Level 5 – 社会性 AI（Social AI）**

**理解人类行为、意图与社会规范。**

* 能预测他人行为
* 感知用户偏好、意图（human-in-the-loop）
* 属于“Human-aligned AI”核心部分
* 需要多模态感知、互动策略、解释机制

**例：** 协作机器人、需要与人类搭档工作的助手型机器人。

---

## **Level 6 – 自我反思 AI（Self-Reflective AI）**

**可以解释自身行为、决策依据，并能自我评估与修正。**

这是本课程特别强调的层级（与 Explainable Robotics 强相关）。

* 具备元认知（Meta-cognition）
* 能回答 “Why?” 与 “Why not?” 类型问题（如 MXRL 模型）
* 可以反思策略并改进
* 可用于高风险场景（医疗、自动驾驶、协作机器人）

**例：** 能解释“我为什么选择左转”的 Robo-agent。

---

## **Level 7 – 道德与价值对齐的 AI（Ethical / Value-aligned AI）**

**最高层级，能理解伦理规范与人类价值并做价值一致性决策。**

* 机器人必须确保行为“合理、可解释、对人类安全”
* 涉及 normative reasoning、value alignment
* 是 Human-aligned intelligent robotics 最终目标

**例：** 在风险场景中选择道德上正确的行动并能解释原因。

---

## 📌 **课程中 Levels of AI 的核心功能与考试重点**

| Level | 能力特征  | 与课程主题关联                 | 考试重点                  |
| ----- | ----- | ----------------------- | --------------------- |
| L0    | 无智能   | —                       | 识别对比                  |
| L1    | 反射规则  | Reactive control        | 与 RL 区分               |
| L2    | 具状态记忆 | MDP、RL                  | 状态基础                  |
| L3    | 有目标   | Optimal policy          | RL 最优策略               |
| L4    | 有环境模型 | Model-based RL          | 规划、预测                 |
| L5    | 社会理解  | Human-robot interaction | intention, multimodal |
| L6    | 自我解释  | Explainable AI / MXRL   | WHY / WHY NOT 问题      |
| L7    | 伦理与价值 | Human-aligned Robotics  | 决策正当性                 |

---

## ⭐考试高频题型总结（极重要）

### **1️⃣ “机器人为何要解释其行为？哪个解释最好？”**

答案通常偏向 Level 6 特征，如：

> “因为这种行为有最高成功概率” （而不是“最高 Q 值”！）

（Exercises Week 10 例题：最佳答案是选项 c）

---

### **2️⃣ “Levels of AI 与 Explainability 的关系？”**

* Level 5 → 需要理解人类
* Level 6 → 能解释自己的行为（如 MXRL）
* Level 7 → 对齐人类价值

---

### **3️⃣ “在 interactive RL 中，人类反馈与 AI 层级的关系？”**

涉及 Level 5（社交 + 理解反馈）、Level 6（解释行动）。

---

### **4️⃣ “MXRL 如何提供 explainable RL？”**

* 统计成功率 Ps 而不是 Q 值
* 是 Level 6 的典型实现

---

## 🎯 最终一句话总结

**Levels of AI 从无智能到完全人类对齐，核心考点是理解机器人从反应式→目标→模型→社会理解→解释→伦理对齐的递进关系，并能举例说明每层的能力与课程中 IRL、XAI 等模块的
